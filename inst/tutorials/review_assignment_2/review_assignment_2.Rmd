---
title: "SDM Course: Review Assignment 2"
output: 
  learnr::tutorial:
    progressive: false
    language:
      en:
        button:
          runcode: Test Code
          submitanswer: Run Code
          questionsubmit: Submit Answer
          questiontryagain: Change my answer
runtime: shiny_prerendered
description: SDM Course Review Assignment 2
---

```{css echo=FALSE}
@media print {
  .topicsContainer,
  .topicActions,
  .exerciseActions .skip {
    display: none;
  }
  .topics .tutorialTitle,
  .topics .section.level2,
  .topics .section.level3:not(.hide) {
    display: block;
  }
  .topics {
    width: 100%;
  }
  .tutorial-exercise, .tutorial-question {
    page-break-inside: avoid;
  }
  .section.level3.done h3 {
    padding-left: 0;
    background-image: none;
  }
  .topics .showSkip .exerciseActions::before {
    content: "Topic not yet completed...";
    font-style: italic;
  }
}
```

```{r setup_hide, include=FALSE}
library(learnr)
library(sdmpack)

custom_checker <- function(label, user_code, check_code, envir_result, evaluate_result, envir_prep, last_value, stage, ...) {
  # this is a code check
  if(stage == "check") {
    
    #fofpack::send_env_to_RStudio(envir_prep)
    
    if(label != "PR_model_tune") {
      rstudioapi::sendToConsole(user_code, focus = TRUE)
    }
    
    sdmpack::set_env(envir_result)
    
    # try(save.image(file.path(system.file(package = "fofpack"), "week_5_progress.Rdata"),
    #            safe = FALSE),
    #     silent = TRUE)

    list(message = "Code Run; Results Now Available in RStudio.", correct = TRUE, type = "success", location = "append")
    
  }

}

tutorial_options(exercise.checker = custom_checker,
                 exercise.timelimit = 1200)

knitr::opts_chunk$set(echo = FALSE)
```

### SDM Course Review Assignment 2 (Week 11)

### Let's Do an SDM

Before you do anything, please make sure to click 'Start over' in the panel to the left. If you can't see the panel use the 'show in new window' icon in the upper left of the Tutorial pane to open the tutorial in a new window, then you should be able to see the left panel.

You will likely have to install one new package, called `butcher`, before you proceed. Don't forget to close this tutorial and reopen it after you install the package. Also, if you have not installed `tidysdm` yet, it is not on CRAN so you cannot use the usual package install method. The easiest way to install it is to run the following:

```{r install_tidysdm}
install.packages("tidysdm", repos = c("https://rdinnager.r-universe.dev", "https://cloud.r-project.org"))
```

We will use our downloaded GBIF data to run a presence-only SDM model. We will be using data on the species Coreopsis leavenworthii (Leavenworth's Tickseed). Coreopsis flowers are the state wildflower of Florida and can be found in Pine Rocklands amongst other habitat types. The download key for the data is `"0032282-231002084531237"`. 

### Setup

```{r setup, include=FALSE}
library(tidyverse)
library(tidymodels)
library(spatialsample)
library(tidysdm)
library(sf)
library(mapview)
library(butcher) 
library(sdmpack)

options(datatable.alloccol = 1024,
        datatable.verbose = FALSE)
```

### Part 1: Run an SDM

First we load our libraries and download the GBIF points. Run the following code to setup.

```{r get_points, exercise=TRUE}
library(tidyverse)
library(tidymodels)
library(sf)
library(rgbif)
library(tidysdm)
library(spatialsample)
library(sdmpack)
library(butcher) ## this one is new
library(mapview)

gbif <- occ_download_get("0032282-231002084531237") %>%
  occ_download_import()
```

```{r get_points-check}
ls()
```

## Exercise 1

Convert the GBIF data into an `sf` object. Replace the blanks with the correct variable names referring to the coordinates in the `gbif` data.frame.

*exercise_1: *
```{r exercise_1, exercise = TRUE}
## convert to sf
gbif <- gbif %>%
  dplyr::select(decimalLongitude,
         decimalLatitude) %>%
  st_as_sf(coords = c("____", "____"), crs = 4326)

mapview(gbif)
```

```{r exercise_1-check}
ls()
```

### Exercise 2: Create Background Area

Fill in the blank to use the 'ecoregion' based method for generating a background area. Use the documentation of `create_background` to find out what methods are available.

*exercise_2: *
```{r exercise_2, exercise=TRUE}
bg <- create_background(gbif, method = ____,
                        buffer = 20000, max_bg = florida)
mapview(bg)

```

```{r exercise_2-check}
ls()
```

```{r codebox, exercise = TRUE}



```

```{r codebox-check}
ls()
```

*question_1: *
```{r question_1}
question_checkbox("What are the possible methods for creating a background area available in `create_background()`? You can use the code box above to try and find the answer (or use the RStudio console if you prefer)",
                  answer("concave_hull", correct = TRUE),
                  answer("convex_hull", correct = TRUE),
                  answer("starship_hull", correct = FALSE),
                  answer("point_buffer", correct = TRUE),
                  answer("pointless_buffer", correct = FALSE),
                  answer("ecoregion", correct = TRUE),
                  answer("grid_fill", correct = TRUE),
                  answer("user_fill", correct = TRUE))
```

### Exercise 3: Sample Pseudo-Absences

Fill in the blanks to sample ten thousand (10000) points from the background area you just created.

*exercise_3: *
```{r exercise_3, exercise=TRUE}
gbif_dat <- sdm_data(gbif, bg = ____, n = ____)
gbif_dat

mapview(gbif_dat, zcol = "present")

```

```{r exercise_3-check}
ls()
```

### Add environmental variables

Use `add_env_vars()` to add environmental variable by running the following code:

```{r env, exercise=TRUE}
gbif_dat <- add_env_vars(gbif_dat, bioclim_fl)
gbif_dat
```

```{r env-check}
ls()
```

### Remove NAs

It is just good data cleaning practice to remove any missing values that you might have in your data. Fill in the blank with the correct function to remove NA values from BIO1 to BIO19. You will have seen this function several times in the course already. 

```{r exercise_4, exercise=TRUE}
gbif_dat <- gbif_dat %>%
  ____(BIO1:BIO19) %>%
  st_sf()

mapview(gbif_dat, zcol = "BIO1")
```

```{r exercise_4-check}
ls()
```

<div id="exercise_4-hint">
**Hint:** The function is in the package `tidyr`. If you type `tidyr::` autocomplete will show you a list of all functions in `tidyr`. Or you can type `?tidyr` in the console and then click the link at the very bottom of the help page where it says 'Index'. This will show you a list of all functions in `tidyr` as well.
</div>

### Spatial Cross Validation

We are going to do spatial cross validation for our model. We will each run 5 folds. Setup the folds and visualize them by running the following:

```{r cv, exercise=TRUE}
## presence only (po) spatial CV
cv_folds_spat <- po_spatial_buffer_vfold_cv(gbif_dat, presence = "present", n = c(24, 16),
                                            v = 5)

## look at the spatial folds
autoplot(cv_folds_spat)
```

```{r cv-check}
ls()
```

### Make a recipe

We are all going to do a simple Generalised Linear Model this time (GLM), with a penalty to help choose the best predictors.
This means to model somewhat more complicated functions of the environment we need to create polynomial terms from our predictors, which can be done in the recipe using `step_poly()`. We will also want to do our usual transformation and normalization. 

```{r recipe, exercise=TRUE}
gbif_recipe <- recipe(gbif_dat, vars = c("present", as_tibble(gbif_dat) %>% dplyr::select(BIO1:BIO19) %>% colnames()),
                         roles = c("outcome", rep("predictor", 19))) %>%
  step_YeoJohnson(BIO1:BIO19) %>%
  step_normalize(BIO1:BIO19) %>%
  step_poly(BIO1:BIO19)

gbif_recipe
```

```{r recipe-check}
ls()
```

Sometimes recipes become very large because they capture the whole R environment. We want to save our workflows later so we want to make our recipe smaller. Run the following code to check the size of the recipe, then cut it down in size using `butcher()`, then check the size again. It should be smaller the second time.

```{r butcher, exercise=TRUE}
butcher::weigh(gbif_recipe)

gbif_recipe <- butcher::butcher(gbif_recipe)

butcher::weigh(gbif_recipe)
```

```{r butcher-check}
ls()
```

### Exercise 5: Make Model and Workflow

Setup the model by filling in the blank. `logistic_reg()` only has two hyper-parameters. We want to tune them both. To find out what they are, don't forget you can use the R documentation. Try typing `?logistic_reg` to see what arguments it takes (and remember that `mode` and `engine` are set by `set_engine()` and `set_mode()`).

*exercise_5: *
```{r exercise_5, exercise=TRUE}
gbif_mod <- logistic_reg(____ = ____, ____ = ____) %>%
  set_engine("glmnet") %>%
  set_mode("classification")

gbif_wf <- workflow() %>%
  add_recipe(gbif_recipe) %>%
  add_model(gbif_mod)

gbif_wf
```

```{r exercise_5-check}
ls()
```

### Tune the Penalty Parameters

Now we tune our model based on our spatial cross validation folds. Using `tune_grid()`, run 25 values of the hyper-parameters. If this is taking much too long, you can try reducing to 16 or 9.

```{r tune, exercise=TRUE}
gbif_tune <- gbif_wf %>%
  tune_grid(cv_folds_spat,
            grid = 25,
            control = control_grid(save_workflow = TRUE), verbose = TRUE)

gbif_tune %>%
  show_best("roc_auc")

```

```{r tune-check}
ls()
```

The `gbif_tune` object is what you need to save for the assignment. Run the following code to open a dialog box and choose where you will save the file. You will need to upload this file to complete the assignment so don't forget where you saved it! The file by default will be called `"tuned_workflows.rds"`, but you can change the file name if you want. Note that the dialog box will pop up twice, just use the same folder (the reason is the tutorial runs the code, then it gets run in RStudio again so that you have access to the object in your environment).

```{r save_file, exercise = TRUE}
write_rds(gbif_tune, file = file.path(rstudioapi::selectDirectory(),
                                      "tuned_workflows.rds"))
```

```{r save_file-check}
ls()
```

### Final Fit

```{r final_fit, exercise=TRUE}
best_params <- gbif_tune %>%
  select_best("roc_auc")

final_wf <- 
  gbif_wf %>% 
  finalize_workflow(best_params)

gbif_fit <- final_wf %>%
  fit(gbif_dat)

```

```{r final_fit-check}
ls()
```

### Have a Look at the Model Coefficients

```{r coefs, exercise=TRUE}
coefs <- gbif_fit %>%
  tidy() %>%
  arrange(desc(abs(estimate)))
coefs
```

```{r coefs-check}
ls()
```

Note that in the general linear model, coefficients are interpretable as an importance measure, because they are calculated using standardised variables. Therefore, they can be thought of as the degree of change in the outcome or response variable with a one standard deviation change in the predictor variable. We can cross-check which coefficients were good predictors with what the variables actually are using `bioclim_vars`.

```{r vars, exercise=TRUE}
bioclim_vars
```

```{r vars-check}
ls()
```

Question 2: Which variable has the highest absolute value for its coefficient?

```{r question_2}
question_text("What is the name of the variable that had the highest absolute coefficient in your model? It could also be a polynomial combination of multiple variables.", answer("jkdsfhdfhkdh8945689456", correct = TRUE),
              incorrect = "Answer recieved. Thank you! If you want to change your answer, click 'Try Again'",
              try_again = "Answer recieved. Thank you! If you want to change your answer, click 'Try Again'",
              allow_retry = TRUE)
```

### Part 2: Visualize the predictions!

Visualise the predictions from you model. Note there are no exercises in this section, it is just for your information (and potentially useful for the final project)

### Make Predictions

```{r grid, exercise=TRUE}
gbif_grid <- sdm_data(gbif, bg,
                         5000, sample_options = list(type = "regular")) %>%
  filter(present == "absent")

gbif_grid_dat <- add_env_vars(gbif_grid, bioclim_fl) %>%
  drop_na(BIO1:BIO19)

gbif_preds <- gbif_fit %>% 
  augment(gbif_grid_dat)

gbif_preds
```

```{r grid-check}
ls()
```

### Visualise the predictions

Run the following to see a map of your model predictions!

```{r box, exercise=TRUE}

coords <- st_coordinates(st_sf(gbif_preds))
ggplot(gbif_preds |> bind_cols(coords), aes(X, Y)) +
  geom_sf(data = bg, inherit.aes = FALSE) +
  geom_raster(aes(fill = .pred_present + 0.0001)) +
  geom_sf(data = gbif, inherit.aes = FALSE, colour = "red",
          size = 1.2) +
  scale_fill_continuous(name = "Probability of Occurrence") +
  theme_minimal()

```

```{r box-check}
ls()
```

## Submit

```{r context="server"}
learnrhash::encoder_logic()
```

Once you have completed the assignment to your satisfaction, please click the 'generate' button below. This will create a text code that you can copy and paste into the assignment text submission form on canvas, and which I can use to regenerate your answers. Please make sure you copy the entire code. The easiest way is to click the copy button in at the top right. This will copy the entire code to the clipboard.

For this assignment you will also have to upload the workflow object file that you saved previously as a file attachment to the assignment.


```{r encode, echo=FALSE}
learnrhash::encoder_ui(ui_before = NULL)
```

### Decode

If you want to double-check the answers that the code above stores, paste it here and click 'Decode!'. 

```{r context="server"}
sdmpack::decoder_logic()
```

```{r decode, echo=FALSE}
sdmpack::decoder_ui()
```


